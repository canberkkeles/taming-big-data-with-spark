{
	"cells": [
		{
			"cell_type": "markdown",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"source": [
				"# AWS Glue Studio Notebook\n",
				"##### You are now running a AWS Glue Studio notebook; To start using your notebook you need to start an AWS Glue Interactive Session.\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"source": [
				"####  Run this cell to set up and start your interactive session.\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"editable": true,
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"%idle_timeout 2880\n",
				"%glue_version 4.0\n",
				"%worker_type G.1X\n",
				"%number_of_workers 5\n",
				"\n",
				"import sys\n",
				"from awsglue.transforms import *\n",
				"from awsglue.utils import getResolvedOptions\n",
				"from pyspark.context import SparkContext\n",
				"from awsglue.context import GlueContext\n",
				"from awsglue.job import Job\n",
				"  \n",
				"sc = SparkContext.getOrCreate()\n",
				"glueContext = GlueContext(sc)\n",
				"spark = glueContext.spark_session\n",
				"job = Job(glueContext)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 4,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"+--------------------+\n",
						"|               value|\n",
						"+--------------------+\n",
						"|Self-Employment: ...|\n",
						"|Achieving Financi...|\n",
						"|       By Frank Kane|\n",
						"|                    |\n",
						"|                    |\n",
						"|                    |\n",
						"|Copyright ï¿½ 2015 ...|\n",
						"|All rights reserv...|\n",
						"|                    |\n",
						"|                    |\n",
						"|            CONTENTS|\n",
						"|          Disclaimer|\n",
						"|             Preface|\n",
						"|Part I: Making th...|\n",
						"|  Overcoming Inertia|\n",
						"|     Fear of Failure|\n",
						"|Career Indoctrina...|\n",
						"|The Carrot on a S...|\n",
						"|      Ego Protection|\n",
						"|Your Employer as ...|\n",
						"+--------------------+\n",
						"only showing top 20 rows\n"
					]
				}
			],
			"source": [
				"from pyspark.sql import functions as func\n",
				"bucket_name = \"BUCKET_NAME\"\n",
				"inputDf = spark.read.text(bucket_name)\n",
				"inputDf.show()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 7,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"+----------+\n",
						"|      word|\n",
						"+----------+\n",
						"|      Self|\n",
						"|Employment|\n",
						"|  Building|\n",
						"|        an|\n",
						"|  Internet|\n",
						"|  Business|\n",
						"|        of|\n",
						"|       One|\n",
						"| Achieving|\n",
						"| Financial|\n",
						"|       and|\n",
						"|  Personal|\n",
						"|   Freedom|\n",
						"|   through|\n",
						"|         a|\n",
						"| Lifestyle|\n",
						"|Technology|\n",
						"|  Business|\n",
						"|        By|\n",
						"|     Frank|\n",
						"+----------+\n",
						"only showing top 20 rows\n"
					]
				}
			],
			"source": [
				"words = inputDf.select(func.explode(func.split(inputDf.value,\"\\\\W+\")).alias(\"word\")) # split the data to words and create new rows using explode function\n",
				"words.filter(words.word != \"\")\n",
				"words.show()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 10,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"+----------+\n",
						"|      word|\n",
						"+----------+\n",
						"|      self|\n",
						"|employment|\n",
						"|  building|\n",
						"|        an|\n",
						"|  internet|\n",
						"|  business|\n",
						"|        of|\n",
						"|       one|\n",
						"| achieving|\n",
						"| financial|\n",
						"|       and|\n",
						"|  personal|\n",
						"|   freedom|\n",
						"|   through|\n",
						"|         a|\n",
						"| lifestyle|\n",
						"|technology|\n",
						"|  business|\n",
						"|        by|\n",
						"|     frank|\n",
						"+----------+\n",
						"only showing top 20 rows\n"
					]
				}
			],
			"source": [
				"lowercase_words = words.select(func.lower(words.word).alias(\"word\"))\n",
				"lowercase_words.show()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 15,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"+--------+-----+\n",
						"|    word|count|\n",
						"+--------+-----+\n",
						"|     you| 1878|\n",
						"|      to| 1828|\n",
						"|    your| 1420|\n",
						"|     the| 1292|\n",
						"|       a| 1191|\n",
						"|      of|  970|\n",
						"|     and|  934|\n",
						"|        |  772|\n",
						"|    that|  747|\n",
						"|      it|  649|\n",
						"|      in|  616|\n",
						"|      is|  560|\n",
						"|     for|  537|\n",
						"|      on|  428|\n",
						"|     are|  424|\n",
						"|      if|  411|\n",
						"|       s|  391|\n",
						"|       i|  387|\n",
						"|business|  383|\n",
						"|     can|  376|\n",
						"+--------+-----+\n",
						"only showing top 20 rows\n"
					]
				}
			],
			"source": [
				"word_counts = lowercase_words.groupBy(\"word\").count().sort(\"count\",ascending=False)\n",
				"word_counts.show()"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## We can also do this with RDDs"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 18,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"import re\n",
				"def normalizeWords(lines):\n",
				"    return re.compile(r'\\W+', re.UNICODE).split(lines.lower())"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 19,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"['self', 'employment', 'building', 'an', 'internet']\n"
					]
				}
			],
			"source": [
				"lines = sc.textFile(bucket_name)\n",
				"words_rdd = lines.flatMap(normalizeWords)\n",
				"words_rdd.take(5)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 20,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"[('', 772), ('book', 39), ('4', 9), ('months', 23), ('once', 59)]\n"
					]
				}
			],
			"source": [
				"result = words_rdd.map(lambda x: (x,1)).reduceByKey(lambda x,y: x+y)\n",
				"result.take(5)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 22,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"[(1878, 'you'), (1828, 'to'), (1420, 'your'), (1292, 'the'), (1191, 'a')]\n"
					]
				}
			],
			"source": [
				"result_sorted = result.map(lambda x : (x[1], x[0])).sortByKey(ascending = False)\n",
				"result_sorted.take(5)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## We can also combine RDDs with DF to get the best of both worlds"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 23,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"import re\n",
				"def normalizeWords(lines):\n",
				"    return re.compile(r'\\W+', re.UNICODE).split(lines.lower())"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 24,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"['self', 'employment', 'building', 'an', 'internet']\n"
					]
				}
			],
			"source": [
				"lines = sc.textFile(bucket_name)\n",
				"words_rdd = lines.flatMap(normalizeWords)\n",
				"words_rdd.take(5)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 25,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"[('self', 111), ('', 772), ('s', 391), ('unlimited', 6), ('where', 53)]\n"
					]
				}
			],
			"source": [
				"result = words_rdd.map(lambda x: (x,1)).reduceByKey(lambda x,y: x+y)\n",
				"result.take(5)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 30,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"from pyspark.sql import Row\n",
				"def createSchema(lines):\n",
				"    return Row(word=str(lines[0]),\n",
				"                       count=int(lines[1]))"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 31,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"+-----------+-----+\n",
						"|       word|count|\n",
						"+-----------+-----+\n",
						"|       self|  111|\n",
						"|           |  772|\n",
						"|          s|  391|\n",
						"|  unlimited|    6|\n",
						"|      where|   53|\n",
						"|       work|  144|\n",
						"|      other|   78|\n",
						"|    results|   25|\n",
						"|     engine|   13|\n",
						"|   avoiding|    5|\n",
						"|       book|   39|\n",
						"|   improved|    2|\n",
						"|   quitting|   10|\n",
						"|        but|  242|\n",
						"|     matter|   13|\n",
						"|        out|  161|\n",
						"|responsibly|    3|\n",
						"|possibility|    3|\n",
						"|       good|   72|\n",
						"|    devoted|    1|\n",
						"+-----------+-----+\n",
						"only showing top 20 rows\n"
					]
				}
			],
			"source": [
				"words_mapped_for_df = result.map(createSchema)\n",
				"words_df_from_rdd = spark.createDataFrame(words_mapped_for_df)\n",
				"words_df_from_rdd.show()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 33,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"+--------+-----+\n",
						"|    word|count|\n",
						"+--------+-----+\n",
						"|     you| 1878|\n",
						"|      to| 1828|\n",
						"|    your| 1420|\n",
						"|     the| 1292|\n",
						"|       a| 1191|\n",
						"|      of|  970|\n",
						"|     and|  934|\n",
						"|        |  772|\n",
						"|    that|  747|\n",
						"|      it|  649|\n",
						"|      in|  616|\n",
						"|      is|  560|\n",
						"|     for|  537|\n",
						"|      on|  428|\n",
						"|     are|  424|\n",
						"|      if|  411|\n",
						"|       s|  391|\n",
						"|       i|  387|\n",
						"|business|  383|\n",
						"|     can|  376|\n",
						"+--------+-----+\n",
						"only showing top 20 rows\n"
					]
				}
			],
			"source": [
				"words_df_from_rdd.sort(\"count\",ascending = False).show()"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Glue PySpark",
			"language": "python",
			"name": "glue_pyspark"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "Python_Glue_Session",
			"pygments_lexer": "python3"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 4
}
